# NeuroView LLM Service - Dependencies
# Optimized for RTX 4060 6GB VRAM, 16GB RAM, Ryzen 5

# Core LLM - Using llama-cpp-python for efficient inference
# Install with CUDA support:
# pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
llama-cpp-python>=0.2.56

# HuggingFace for model downloads and tokenizers
huggingface-hub>=0.20.0
transformers>=4.36.0
tokenizers>=0.15.0

# Embeddings and Sentence Transformers
sentence-transformers>=2.2.2

# Vector Store Options
chromadb>=0.4.22
# faiss-cpu>=1.7.4  # Optional: uncomment if using FAISS

# API Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
pydantic>=2.5.0

# Document Processing
PyPDF2>=3.0.0
python-docx>=1.1.0

# Utilities
numpy>=1.24.0
tqdm>=4.66.0
python-dotenv>=1.0.0

# Optional: For fine-tuning (requires more VRAM)
# Uncomment when setting up fine-tuning
# torch>=2.1.0
# bitsandbytes>=0.42.0
# peft>=0.8.0
# datasets>=2.16.0
# accelerate>=0.26.0
# trl>=0.7.10

# Optional: For hybrid retrieval
# rank-bm25>=0.2.2

# Development
pytest>=7.4.0
black>=24.1.0
isort>=5.13.0

